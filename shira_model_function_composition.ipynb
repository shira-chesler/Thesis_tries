{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shira-chesler/Thesis_tries/blob/main/shira_model_function_composition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRkrhPWtzHqE",
        "outputId": "e9851da1-07c7-4976-d9f6-3a26aa4f080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSV7GSUzoEdE",
        "outputId": "936266e5-c16c-4fb6-c398-19f6ef48f69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LOs4j5_31CXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.set_device(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5xqY4Vuou27",
        "outputId": "2fb3326e-6017-403e-a0ed-714bca759aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "training_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=20, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=20, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_z-3pTM1Jl8",
        "outputId": "d9c0dfa9-b178-46e5-bb73-6c4b57019144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------2222dddd222222igggjdd222222First model-------------------------"
      ],
      "metadata": {
        "id": "sw0aOaBY2UGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class MyLinearLayer(torch.nn.Module):\n",
        "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
        "    def __init__(self, size_in, size_out):\n",
        "        super().__init__()\n",
        "        self.size_in, self.size_out = size_in, size_out\n",
        "        weights = torch.Tensor(size_in, size_out)\n",
        "        self.weights = torch.nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
        "        bias = torch.Tensor(1, size_out)\n",
        "        self.bias = torch.nn.Parameter(bias)\n",
        "\n",
        "        # initialize weights and biases\n",
        "        torch.nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
        "        fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
        "        bound = 1 / math.sqrt(fan_in)\n",
        "        torch.nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
        "\n",
        "        self.weights = torch.nn.Parameter(torch.cat((self.bias.t(), self.weights.t()), axis = 1))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(1, size_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        #add 1 in vector x\n",
        "        # print(x.shape, torch.ones(1, x.shape[1]).shape)\n",
        "        x = torch.cat((torch.ones(x.shape[0], 1), x), axis = 1)\n",
        "        # print(\"bias size:\", self.bias.t().shape)\n",
        "        # print(\"weight size\", self.weights.t().shape)\n",
        "        # weight_with_bias = torch.cat((self.bias.t().reshape(1, self.bias.t().shape[0]), self.weights.t()), axis = 0)\n",
        "        # print(x.shape)\n",
        "        # print(self.weights.t().shape)\n",
        "        # print(\"x: \", x.shape, \"w: \", self.weights.t().shape)\n",
        "        w_times_x = torch.mm(x, self.weights.t())\n",
        "        return w_times_x"
      ],
      "metadata": {
        "id": "YLB8xW1TCx1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(SimpleModel, self).__init__()\n",
        "      self.flatten = torch.nn.Flatten()\n",
        "      self.linear1 = torch.nn.Linear(3072, 4)\n",
        "      self.activation1 = torch.nn.ReLU()\n",
        "      self.linear2 = MyLinearLayer(4, 8)\n",
        "      self.activation2 = torch.nn.ReLU()\n",
        "      self.linear3 = MyLinearLayer(8, 10)\n",
        "      self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      x = self.linear1(x)\n",
        "      x = self.activation1(x)\n",
        "      x = self.linear2(x)\n",
        "      x = self.activation2(x)\n",
        "      x = self.linear3(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "first_model = SimpleModel()"
      ],
      "metadata": {
        "id": "oLMAOCFJqouq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(first_model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "DqbWzn-Rrcup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "\n",
        "    for i, data in enumerate(training_loader):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = first_model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "            current_loss = running_loss / 1000  # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, current_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train_batch', current_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    avg_loss = running_loss / len(training_loader)\n",
        "    tb_writer.add_scalar('Loss/train_epoch', avg_loss, epoch_index + 1)\n",
        "    print('Epoch {} average loss: {}'.format(epoch_index, avg_loss))\n",
        "\n",
        "    return avg_loss\n"
      ],
      "metadata": {
        "id": "PfuADHRwsXnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    first_model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch + 1, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    first_model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "          for i, vdata in tqdm(enumerate(validation_loader), total=len(validation_loader)):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = first_model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "            avg_vloss = running_vloss / (i + 1)\n",
        "            # print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "            # Log the running loss averaged per batch\n",
        "            # for both training and validation\n",
        "            writer.add_scalars('Training vs. Validation Loss',\n",
        "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                            epoch_number + 1)\n",
        "            writer.flush()\n",
        "\n",
        "            # Track best performance, and save the model's state\n",
        "            if avg_vloss < best_vloss:\n",
        "                best_vloss = avg_vloss\n",
        "                model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "                torch.save(first_model.state_dict(), model_path)\n",
        "\n",
        "            epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eeQgrQEtr_E",
        "outputId": "48c63d86-4508-4f0a-d470-1a975a04a3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.30267742562294\n",
            "  batch 2000 loss: 2.302058845758438\n",
            "Epoch 1 average loss: 0.4603355540275574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 245.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.3011601157188415\n",
            "  batch 2000 loss: 2.300096718788147\n",
            "Epoch 2 average loss: 0.459809529209137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 266.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 3:\n",
            "  batch 1000 loss: 2.2939949424266817\n",
            "  batch 2000 loss: 2.2768335988521575\n",
            "Epoch 3 average loss: 0.45203308391571045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 218.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 4:\n",
            "  batch 1000 loss: 2.2450287343263624\n",
            "  batch 2000 loss: 2.2339828469753265\n",
            "Epoch 4 average loss: 0.4448083688735962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 200.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 5:\n",
            "  batch 1000 loss: 2.213556687116623\n",
            "  batch 2000 loss: 2.2079639376401903\n",
            "Epoch 5 average loss: 0.44033006067276004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 261.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a pretrained model\n",
        "pretrained_model = first_model\n",
        "\n",
        "# Create empty dictionaries to store weights and biases\n",
        "weights_dict = {}\n",
        "biases_dict = {}\n",
        "\n",
        "# Loop through named parameters and separate weights and biases\n",
        "for name, param in pretrained_model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        weights_dict[name] = {'values': param.data}\n",
        "    elif 'bias' in name:\n",
        "        biases_dict[name] = {'values': param.data}\n",
        "\n",
        "# Print or use the dictionaries as needed\n",
        "print(\"Weights:\")\n",
        "for name, weight_info in weights_dict.items():\n",
        "    print(f\"{name}: {weight_info['values']}\")\n",
        "\n",
        "print(\"\\nBiases:\")\n",
        "for name, bias_info in biases_dict.items():\n",
        "    print(f\"{name}: {bias_info['values']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVgR9fOr2PnU",
        "outputId": "22c710b0-abc4-41e4-bb48-415ea3e3fca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights:\n",
            "linear1.weight: tensor([[ 0.0051, -0.0109, -0.0134,  ..., -0.0040,  0.0027,  0.0017],\n",
            "        [ 0.0269,  0.0241,  0.0337,  ..., -0.0123,  0.0015, -0.0125],\n",
            "        [-0.0224, -0.0223, -0.0128,  ..., -0.0117, -0.0044, -0.0146],\n",
            "        [-0.0102, -0.0151, -0.0137,  ...,  0.0135,  0.0161,  0.0035]])\n",
            "linear2.weights: tensor([[ 0.0837, -0.0039, -0.2401, -0.0642, -0.1319],\n",
            "        [ 0.0380,  0.4827, -0.0205,  0.0570, -0.1938],\n",
            "        [ 0.4209, -0.4782,  0.7862, -0.1284,  0.2963],\n",
            "        [ 0.0903,  0.3750, -0.0516,  0.3940,  0.4866],\n",
            "        [ 0.2186,  0.5517, -0.0586, -0.2068, -0.0029],\n",
            "        [ 0.2117,  0.5269,  0.0459, -0.3604, -0.3269],\n",
            "        [ 0.1510,  0.1431,  0.3781,  0.4818, -0.5797],\n",
            "        [-0.2690,  0.4615,  0.0696, -0.5976, -0.0938]])\n",
            "linear3.weights: tensor([[-0.0618,  0.1792,  0.2288, -0.5460,  0.2095,  0.3731,  0.3982, -0.5379,\n",
            "          0.3945],\n",
            "        [-0.1426, -0.2694,  0.1873,  0.3319, -0.2772,  0.1929,  0.1849, -0.0798,\n",
            "          0.1765],\n",
            "        [ 0.1317, -0.0610, -0.2998,  0.2107,  0.1599,  0.0976, -0.0870, -0.1004,\n",
            "         -0.1836],\n",
            "        [-0.0689,  0.2793,  0.0702, -0.1369, -0.0495, -0.2786, -0.1948,  0.0119,\n",
            "          0.0854],\n",
            "        [ 0.2391, -0.0759,  0.1453, -0.1302, -0.3087,  0.1619, -0.2798, -0.0063,\n",
            "          0.1588],\n",
            "        [ 0.2383,  0.2530,  0.0560, -0.2668,  0.4895, -0.0530, -0.1231,  0.3897,\n",
            "         -0.5788],\n",
            "        [ 0.0627, -0.1941, -0.3943,  0.6422,  0.2173, -0.4491, -0.3138, -0.1892,\n",
            "         -0.1277],\n",
            "        [-0.2175, -0.3161,  0.0216,  0.1087,  0.2129,  0.1110,  0.0685, -0.3175,\n",
            "          0.0380],\n",
            "        [-0.1195, -0.3055,  0.2863, -0.2425, -0.4924,  0.3683,  0.5411,  0.2896,\n",
            "          0.3844],\n",
            "        [-0.0933,  0.0683, -0.2825,  0.0658,  0.1277,  0.2284, -0.0708, -0.3456,\n",
            "         -0.0525]])\n",
            "\n",
            "Biases:\n",
            "linear1.bias: tensor([-0.1015,  0.0718,  0.0227,  0.0447])\n",
            "linear2.bias: tensor([[0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "linear3.bias: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------Second model-------------------------"
      ],
      "metadata": {
        "id": "AyAzoV_M2JKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(SimpleModel2, self).__init__()\n",
        "      self.flatten = torch.nn.Flatten()\n",
        "      self.linear1 = MyLinearLayer(3072, 4)\n",
        "      self.activation1 = torch.nn.ReLU()\n",
        "      self.linear2 = MyLinearLayer(4, 10)\n",
        "      self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      x = self.linear1(x)\n",
        "      x = self.activation1(x)\n",
        "      x = self.linear2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "second_model = SimpleModel2()"
      ],
      "metadata": {
        "id": "K1L6DrxW4XBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------Linear algebric Operations---------------"
      ],
      "metadata": {
        "id": "K4OvKx_jotmf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwCvuZZuaT0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in first_model.named_parameters():\n",
        "  if name == 'linear2.weights':\n",
        "    print(param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHCQunRKAND",
        "outputId": "8686032d-930c-469c-d915-ec4e2bf38668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 5])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0837, -0.0039, -0.2401, -0.0642, -0.1319],\n",
            "        [ 0.0380,  0.4827, -0.0205,  0.0570, -0.1938],\n",
            "        [ 0.4209, -0.4782,  0.7862, -0.1284,  0.2963],\n",
            "        [ 0.0903,  0.3750, -0.0516,  0.3940,  0.4866],\n",
            "        [ 0.2186,  0.5517, -0.0586, -0.2068, -0.0029],\n",
            "        [ 0.2117,  0.5269,  0.0459, -0.3604, -0.3269],\n",
            "        [ 0.1510,  0.1431,  0.3781,  0.4818, -0.5797],\n",
            "        [-0.2690,  0.4615,  0.0696, -0.5976, -0.0938]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(weights_dict['linear2.weights']['values'].shape)\n",
        "print(weights_dict['linear3.weights']['values'].shape)\n",
        "relu_of_first = torch.relu(weights_dict['linear2.weights']['values'])\n",
        "new_first = torch.cat(torch.ones(1),axis=1)\n",
        "new_weights = torch.mm(weights_dict['linear3.weights']['values'], new_first)\n",
        "print(new_weights.shape)"
      ],
      "metadata": {
        "id": "lk2OMyB04lj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "28f5b31e-bf7e-4afa-a141-3877115044ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 5])\n",
            "torch.Size([10, 9])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cat() received an invalid combination of arguments - got (Tensor, axis=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8b6a96e4d024>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear3.weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrelu_of_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear2.weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnew_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnew_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear3.weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, axis=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
          ]
        }
      ]
    }
  ]
}